{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4b4c7d0",
   "metadata": {},
   "source": [
    "### Objetivo del estudio\n",
    "\n",
    "El cliente es el jefe del área de Revenue Management, de una empresa multinacional proveedora del sector de Alimentos y Bebidas del mercado interno de Argentina.\n",
    "\n",
    "El cliente afirma no tener sensibilidad acerca de la relación entre aumentos de precio y el impacto en la demanda de los productos de las categorías que maneja. El mercado en el que trabaja atraviesa aceleraciones y desaceleraciones en la inflación, además de fuertes oscilaciones en el consumo. El cliente no entiende si una variación en el consumo será:\n",
    "   1. Relativa contra una variación del precio del producto en sí mismo.\n",
    "   2. Relativa contra una variación del precio vs la inflación en general.\n",
    "   3. Relativa contra una variación del precio vs la variación de precios de la categoría de productos.\n",
    "\n",
    "Por otro lado, el cliente reconoce no tener sensibilidad acerca de la elasticidad cruzada de la demanda sobre el precio de la competencia. Su estrategia comercial tiene bien definido el principal producto competidor de cada uno de sus productos, pero no logra reconocer el impacto de la demanda relativo al mismo.\n",
    "\n",
    "El cliente quiere basar su investigación de mercado en los datos de una consultora que contrata, la cual tiene datos de cantidades y de ventas de productos de las categorías que trabaja.\n",
    "\n",
    "En este contexto, el cliente te contrata para responder las siguientes preguntas:\n",
    "1. De las tres variables explicativas planteadas, ¿cuál es la variable que mejor explica una variación en el consumo?\n",
    "    1. Relativa contra una variación del precio del producto en sí mismo.\n",
    "    2. Relativa contra una variación del precio vs la inflación en general.\n",
    "    3. Relativa contra una variación del precio vs la variación de precios de la categoría de productos.\n",
    "\n",
    "2. Tomando como variable explicativa la respondida arriba, ¿cuál es el impacto esperado de la demanda al aumentar el precio en 1% en cada producto? ¿Este resultado puede variar en contextos de mayor o menor inflación, o de mayor o menor consumo?\n",
    "3. ¿Cuál es el impacto esperado en la demanda de los productos al aumentar el precio de la competencia directa en 1%? ¿El impacto es similar si la competencia directa en su lugar disminuye el precio en 1%?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2270e64",
   "metadata": {},
   "source": [
    "### Acerca del dataset de Ventas Retail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6be0ba",
   "metadata": {},
   "source": [
    "El dataset principal de Ventas Retail compartido es subido de manera semanal con la siguiente estructura:\n",
    "\n",
    "    Archivo AR_VTA... : Archivo de Cantidad y Facturación vendida, con nivel de granularidad cliente-producto cerrado por semana.\n",
    "    Al realizar una unión de los archivos VTA pueden haber registros duplicados, ya que cada archivo individual suele incluir información de más de una semana por archivo, debido al proceso interno de la consultora.\n",
    "\n",
    "    Archivo AR_PRD : Archivo maestro de Productos (También denominados 'SKUs'), correspondientes a los datos del archivo AR_VTA del .zip correspondiente.\n",
    "    Al ser el archivo maestro de Productos de sólo el .zip correspondiente, al realizar una unión de todos los maestros, es posible que hayan registros duplicados.\n",
    "        \n",
    "    Archivo AR_PDV : Archivo maestro de Clientes (También denominados 'PDVs'), correspondientes a los datos del archivo AR_VTA del .zip correspondiente.\n",
    "    Similar al caso anterior, al realizar una unión de todos los maestros, es posible que hayan registros duplicados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c725f64",
   "metadata": {},
   "source": [
    "El dataset original suele ser subido en un servidor FTP, en distintos archivos de extensión .zip , cada uno de ellos con un archivo AR_VTA , AR_PRD , y AR_PDV . Hemos subido una serie de archivos .zip anonimizados a nuestro github para realizar el data wrangling de la manera más fiel al caso real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb67ef83",
   "metadata": {},
   "source": [
    "### Carga del dataset principal de Ventas Retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "45f6fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143d0e8d",
   "metadata": {},
   "source": [
    "##### Listado de archivos .zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "49314a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos zip: \n",
      "['VENTAS_SEMANAL_20240615.zip', 'VENTAS_SEMANAL_20240608.zip', 'VENTAS_SEMANAL_20240601.zip', 'VENTAS_SEMANAL_20240525.zip', 'VENTAS_SEMANAL_20240518.zip', 'VENTAS_SEMANAL_20240511.zip', 'VENTAS_SEMANAL_20240504.zip', 'VENTAS_SEMANAL_20240427.zip', 'VENTAS_SEMANAL_20240420.zip', 'VENTAS_SEMANAL_20240413.zip', 'VENTAS_SEMANAL_20240406.zip', 'VENTAS_SEMANAL_20240330.zip', 'VENTAS_SEMANAL_20240323.zip', 'VENTAS_SEMANAL_20240316.zip', 'VENTAS_SEMANAL_20240309.zip']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# URL de la API de GitHub para listar los contenidos del directorio\n",
    "api_url = 'https://api.github.com/repos/Hart-Hunt/Nuevo-BTC/contents/Dataset'\n",
    "\n",
    "# Encabezados de la solicitud (opcional: agrega tu token de acceso personal si tienes problemas de tasa de solicitud)\n",
    "headers = {\n",
    "    'Accept': 'application/vnd.github.v3+json',\n",
    "    # 'Authorization': 'token YOUR_PERSONAL_ACCESS_TOKEN'  # Opcional: usar token si es necesario\n",
    "}\n",
    "\n",
    "# Realizar la solicitud a la API de GitHub\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()  # Lanzar un error si la solicitud falla\n",
    "\n",
    "# Filtrar la lista de archivos para obtener solo los archivos ZIP\n",
    "zip_files = [file_info['name'] for file_info in response.json() if file_info['name'].endswith('.zip')]\n",
    "\n",
    "# Ordenar el listado de archivos en orden alfabético descendiente\n",
    "zip_files.sort(reverse=True)\n",
    "\n",
    "# URL base para descargar los archivos ZIP\n",
    "base_url = 'https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/'\n",
    "\n",
    "print(\"Archivos zip: \")\n",
    "print(zip_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7ff61",
   "metadata": {},
   "source": [
    "La consultora nos ha informado que dentro de sus procesos internos, pueden realizar limpieza de sus datos, y que los archivos maestros más recientes tengan datos más validados, y/o con información en mayor cantidad de campos de sus clientes y/o productos.\n",
    "\n",
    "\n",
    "Por esto último, se ordenaron los archivos de manera alfabética descendiente. Luego, en cada dataset se eliminarán registros duplicados para conservar sólo el más reciente de los mismos, que por proceso debe de ser el que tenga la mejor información disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349ac7f",
   "metadata": {},
   "source": [
    "##### Descarga archivos base PDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "89578b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando Base PDV...\n",
      "Procesando AR_PDV_20240615.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240615.zip\n",
      "Procesando AR_PDV_20240608.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240608.zip\n",
      "Procesando AR_PDV_20240601.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240601.zip\n",
      "Procesando AR_PDV_20240525.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240525.zip\n",
      "Procesando AR_PDV_20240518.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240518.zip\n",
      "Procesando AR_PDV_20240511.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240511.zip\n",
      "Procesando AR_PDV_20240504.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240504.zip\n",
      "Procesando AR_PDV_20240427.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240427.zip\n",
      "Procesando AR_PDV_20240420.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240420.zip\n",
      "Procesando AR_PDV_20240413.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240413.zip\n",
      "Procesando AR_PDV_20240406.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240406.zip\n",
      "Procesando AR_PDV_20240330.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240330.zip\n",
      "Procesando AR_PDV_20240323.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240323.zip\n",
      "Procesando AR_PDV_20240316.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240316.zip\n",
      "Procesando AR_PDV_20240309.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240309.zip\n",
      "Base df_PDV procesada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Descargando Base PDV...\")\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y descomprimir cada archivo ZIP\n",
    "for zip_file in zip_files:\n",
    "    zip_url = base_url + zip_file\n",
    "    response = requests.get(zip_url)\n",
    "    \n",
    "#     print(f\"Descargando {zip_file} desde {zip_url}\")\n",
    "    \n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "#         print(f\"Archivos en {zip_file}: {z.namelist()}\")\n",
    "        \n",
    "        for filename in z.namelist():\n",
    "            if filename.startswith('AR_PDV') and filename.endswith('.csv'):\n",
    "                print(f\"Procesando {filename} desde {zip_url}\")\n",
    "                with z.open(filename) as f:\n",
    "                    df = pd.read_csv(f, delimiter=',')\n",
    "                    dataframes.append(df)\n",
    "\n",
    "# Verificar si se encontraron archivos y se cargaron en dataframes\n",
    "if not dataframes:\n",
    "    print(\"No se encontraron archivos CSV que comiencen con 'AR_PDV'.\")\n",
    "else:\n",
    "    # Combinar todos los DataFrames en uno solo\n",
    "    df_PDV_000 = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Base df_PDV_000 procesada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0b7c818a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO_UNICO_PDV</th>\n",
       "      <th>AREA_P</th>\n",
       "      <th>ZONA_P</th>\n",
       "      <th>CLUSTER_PDV</th>\n",
       "      <th>ZONA_MODELO_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101890</td>\n",
       "      <td>Interior</td>\n",
       "      <td>MENDOZA INTERIOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CUYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9074242</td>\n",
       "      <td>Interior</td>\n",
       "      <td>MENDOZA INTERIOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CUYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5770686</td>\n",
       "      <td>Interior</td>\n",
       "      <td>ROSARIO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITORAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5349829</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>LA PLATA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SUB SUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8712656</td>\n",
       "      <td>Interior</td>\n",
       "      <td>MENDOZA INTERIOR</td>\n",
       "      <td>Autoservicio Chico</td>\n",
       "      <td>CUYO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27292</th>\n",
       "      <td>889250</td>\n",
       "      <td>Interior</td>\n",
       "      <td>CHACO INTERIOR</td>\n",
       "      <td>Autoservicio Mediano</td>\n",
       "      <td>NEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27293</th>\n",
       "      <td>3635844</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>LA PLATA</td>\n",
       "      <td>Autoservicio Mediano</td>\n",
       "      <td>SUB SUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27294</th>\n",
       "      <td>867274</td>\n",
       "      <td>Interior</td>\n",
       "      <td>MISIONES POSADAS</td>\n",
       "      <td>Autoservicio Chico</td>\n",
       "      <td>NEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27295</th>\n",
       "      <td>6775848</td>\n",
       "      <td>Metropolitana</td>\n",
       "      <td>GBA NORTE</td>\n",
       "      <td>Grupo Cadena</td>\n",
       "      <td>SUB NORTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27296</th>\n",
       "      <td>602547</td>\n",
       "      <td>Interior</td>\n",
       "      <td>CORDOBA INTERIOR</td>\n",
       "      <td>Autoservicio Chico</td>\n",
       "      <td>CORDOBA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27297 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CODIGO_UNICO_PDV         AREA_P            ZONA_P  \\\n",
       "0                101890       Interior  MENDOZA INTERIOR   \n",
       "1               9074242       Interior  MENDOZA INTERIOR   \n",
       "2               5770686       Interior           ROSARIO   \n",
       "3               5349829  Metropolitana          LA PLATA   \n",
       "4               8712656       Interior  MENDOZA INTERIOR   \n",
       "...                 ...            ...               ...   \n",
       "27292            889250       Interior    CHACO INTERIOR   \n",
       "27293           3635844  Metropolitana          LA PLATA   \n",
       "27294            867274       Interior  MISIONES POSADAS   \n",
       "27295           6775848  Metropolitana         GBA NORTE   \n",
       "27296            602547       Interior  CORDOBA INTERIOR   \n",
       "\n",
       "                CLUSTER_PDV ZONA_MODELO_B  \n",
       "0                       NaN          CUYO  \n",
       "1                       NaN          CUYO  \n",
       "2                       NaN       LITORAL  \n",
       "3                       NaN       SUB SUR  \n",
       "4        Autoservicio Chico          CUYO  \n",
       "...                     ...           ...  \n",
       "27292  Autoservicio Mediano           NEA  \n",
       "27293  Autoservicio Mediano       SUB SUR  \n",
       "27294    Autoservicio Chico           NEA  \n",
       "27295          Grupo Cadena     SUB NORTE  \n",
       "27296    Autoservicio Chico       CORDOBA  \n",
       "\n",
       "[27297 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_PDV_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30334b26",
   "metadata": {},
   "source": [
    "##### Descarga archivos base SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3520ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando Base SKU...\n",
      "Procesando AR_PRD_20240615.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240615.zip\n",
      "Procesando AR_PRD_20240608.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240608.zip\n",
      "Procesando AR_PRD_20240601.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240601.zip\n",
      "Procesando AR_PRD_20240525.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240525.zip\n",
      "Procesando AR_PRD_20240518.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240518.zip\n",
      "Procesando AR_PRD_20240511.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240511.zip\n",
      "Procesando AR_PRD_20240504.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240504.zip\n",
      "Procesando AR_PRD_20240427.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240427.zip\n",
      "Procesando AR_PRD_20240420.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240420.zip\n",
      "Procesando AR_PRD_20240413.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240413.zip\n",
      "Procesando AR_PRD_20240406.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240406.zip\n",
      "Procesando AR_PRD_20240330.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240330.zip\n",
      "Procesando AR_PRD_20240323.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240323.zip\n",
      "Procesando AR_PRD_20240316.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240316.zip\n",
      "Procesando AR_PRD_20240309.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240309.zip\n",
      "Base df_SKU procesada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Descargando Base SKU...\")\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y descomprimir cada archivo ZIP\n",
    "for zip_file in zip_files:\n",
    "    zip_url = base_url + zip_file\n",
    "    response = requests.get(zip_url)\n",
    "    \n",
    "#     print(f\"Descargando {zip_file} desde {zip_url}\")\n",
    "    \n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "#         print(f\"Archivos en {zip_file}: {z.namelist()}\")\n",
    "        \n",
    "        for filename in z.namelist():\n",
    "            if filename.startswith('AR_PRD') and filename.endswith('.csv'):\n",
    "                print(f\"Procesando {filename} desde {zip_url}\")\n",
    "                with z.open(filename) as f:\n",
    "                    df = pd.read_csv(f, delimiter=',')\n",
    "                    dataframes.append(df)\n",
    "\n",
    "# Verificar si se encontraron archivos y se cargaron en dataframes\n",
    "if not dataframes:\n",
    "    print(\"No se encontraron archivos CSV que comiencen con 'AR_PRD'.\")\n",
    "else:\n",
    "    # Combinar todos los DataFrames en uno solo\n",
    "    df_SKU_000 = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Base df_SKU_000 procesada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f702b257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODIGO_BARRAS_SKU</th>\n",
       "      <th>CATEGORIA_SKU</th>\n",
       "      <th>MARCA_SKU</th>\n",
       "      <th>PROVEEDOR_SKU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99087187</td>\n",
       "      <td>C340</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95111198</td>\n",
       "      <td>C340</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93510361</td>\n",
       "      <td>C158</td>\n",
       "      <td>M1645</td>\n",
       "      <td>P4207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97971498</td>\n",
       "      <td>C353</td>\n",
       "      <td>M6800</td>\n",
       "      <td>P9774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90452684</td>\n",
       "      <td>C457</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32415</th>\n",
       "      <td>98498281</td>\n",
       "      <td>C749</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32416</th>\n",
       "      <td>98877739</td>\n",
       "      <td>C749</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>96591546</td>\n",
       "      <td>C749</td>\n",
       "      <td>M536</td>\n",
       "      <td>P9514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32418</th>\n",
       "      <td>94233816</td>\n",
       "      <td>C920</td>\n",
       "      <td>M9037</td>\n",
       "      <td>P6496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32419</th>\n",
       "      <td>93495980</td>\n",
       "      <td>C340</td>\n",
       "      <td>OTRAS MARCAS</td>\n",
       "      <td>OTROS PROVEEDORES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32420 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CODIGO_BARRAS_SKU CATEGORIA_SKU     MARCA_SKU      PROVEEDOR_SKU\n",
       "0               99087187          C340  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "1               95111198          C340  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "2               93510361          C158         M1645              P4207\n",
       "3               97971498          C353         M6800              P9774\n",
       "4               90452684          C457  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "...                  ...           ...           ...                ...\n",
       "32415           98498281          C749  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "32416           98877739          C749  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "32417           96591546          C749          M536              P9514\n",
       "32418           94233816          C920         M9037              P6496\n",
       "32419           93495980          C340  OTRAS MARCAS  OTROS PROVEEDORES\n",
       "\n",
       "[32420 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SKU_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5cac3a",
   "metadata": {},
   "source": [
    "##### Descarga archivos base Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed5fd253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando Base Ventas...\n",
      "Procesando AR_VTA_20240615.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240615.zip\n",
      "Procesando AR_VTA_20240608.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240608.zip\n",
      "Procesando AR_VTA_20240601.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240601.zip\n",
      "Procesando AR_VTA_20240525.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240525.zip\n",
      "Procesando AR_VTA_20240518.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240518.zip\n",
      "Procesando AR_VTA_20240511.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240511.zip\n",
      "Procesando AR_VTA_20240504.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240504.zip\n",
      "Procesando AR_VTA_20240427.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240427.zip\n",
      "Procesando AR_VTA_20240420.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240420.zip\n",
      "Procesando AR_VTA_20240413.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240413.zip\n",
      "Procesando AR_VTA_20240406.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240406.zip\n",
      "Procesando AR_VTA_20240330.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240330.zip\n",
      "Procesando AR_VTA_20240323.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240323.zip\n",
      "Procesando AR_VTA_20240316.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240316.zip\n",
      "Procesando AR_VTA_20240309.csv desde https://github.com/Hart-Hunt/Nuevo-BTC/raw/main/Dataset/VENTAS_SEMANAL_20240309.zip\n",
      "Base df_VTA procesada.\n"
     ]
    }
   ],
   "source": [
    "print(\"Descargando Base Ventas...\")\n",
    "\n",
    "# Lista para almacenar los DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Descargar y descomprimir cada archivo ZIP\n",
    "for zip_file in zip_files:\n",
    "    zip_url = base_url + zip_file\n",
    "    response = requests.get(zip_url)\n",
    "    \n",
    "#     print(f\"Descargando {zip_file} desde {zip_url}\")\n",
    "    \n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "#         print(f\"Archivos en {zip_file}: {z.namelist()}\")\n",
    "        \n",
    "        for filename in z.namelist():\n",
    "            if filename.startswith('AR_VTA') and filename.endswith('.csv'):\n",
    "                print(f\"Procesando {filename} desde {zip_url}\")\n",
    "                with z.open(filename) as f:\n",
    "                    df = pd.read_csv(f, delimiter=',')\n",
    "                    dataframes.append(df)\n",
    "\n",
    "# Verificar si se encontraron archivos y se cargaron en dataframes\n",
    "if not dataframes:\n",
    "    print(\"No se encontraron archivos CSV que comiencen con 'AR_VTA'.\")\n",
    "else:\n",
    "    # Combinar todos los DataFrames en uno solo\n",
    "    df_VTA_000 = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Base df_VTA_000 procesada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7664e6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Semana_Inicio_Semana</th>\n",
       "      <th>CODIGO_UNICO_PDV_2</th>\n",
       "      <th>Codigo_Barras_SKU</th>\n",
       "      <th>Cantidad_de_Venta</th>\n",
       "      <th>Facturación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20240518</td>\n",
       "      <td>6260235</td>\n",
       "      <td>98804537</td>\n",
       "      <td>8</td>\n",
       "      <td>21709,92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20240518</td>\n",
       "      <td>9396116</td>\n",
       "      <td>94870312</td>\n",
       "      <td>9</td>\n",
       "      <td>13500,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20240518</td>\n",
       "      <td>1500200</td>\n",
       "      <td>94870312</td>\n",
       "      <td>26</td>\n",
       "      <td>39575,43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20240511</td>\n",
       "      <td>1422811</td>\n",
       "      <td>95183683</td>\n",
       "      <td>1</td>\n",
       "      <td>1000,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20240525</td>\n",
       "      <td>9750111</td>\n",
       "      <td>92831741</td>\n",
       "      <td>3</td>\n",
       "      <td>5670,00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615557</th>\n",
       "      <td>20230109</td>\n",
       "      <td>1024492</td>\n",
       "      <td>97933774</td>\n",
       "      <td>1</td>\n",
       "      <td>413,01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615558</th>\n",
       "      <td>20230102</td>\n",
       "      <td>3949987</td>\n",
       "      <td>91263083</td>\n",
       "      <td>4</td>\n",
       "      <td>1652,04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615559</th>\n",
       "      <td>20230116</td>\n",
       "      <td>7889835</td>\n",
       "      <td>97933774</td>\n",
       "      <td>5</td>\n",
       "      <td>2065,05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615560</th>\n",
       "      <td>20230327</td>\n",
       "      <td>9778655</td>\n",
       "      <td>93649198</td>\n",
       "      <td>8</td>\n",
       "      <td>1251,53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615561</th>\n",
       "      <td>20230102</td>\n",
       "      <td>2382001</td>\n",
       "      <td>91788997</td>\n",
       "      <td>1</td>\n",
       "      <td>398,07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3615562 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Semana_Inicio_Semana  CODIGO_UNICO_PDV_2  Codigo_Barras_SKU  \\\n",
       "0                    20240518             6260235           98804537   \n",
       "1                    20240518             9396116           94870312   \n",
       "2                    20240518             1500200           94870312   \n",
       "3                    20240511             1422811           95183683   \n",
       "4                    20240525             9750111           92831741   \n",
       "...                       ...                 ...                ...   \n",
       "3615557              20230109             1024492           97933774   \n",
       "3615558              20230102             3949987           91263083   \n",
       "3615559              20230116             7889835           97933774   \n",
       "3615560              20230327             9778655           93649198   \n",
       "3615561              20230102             2382001           91788997   \n",
       "\n",
       "         Cantidad_de_Venta Facturación  \n",
       "0                        8    21709,92  \n",
       "1                        9    13500,00  \n",
       "2                       26    39575,43  \n",
       "3                        1     1000,00  \n",
       "4                        3     5670,00  \n",
       "...                    ...         ...  \n",
       "3615557                  1      413,01  \n",
       "3615558                  4     1652,04  \n",
       "3615559                  5     2065,05  \n",
       "3615560                  8     1251,53  \n",
       "3615561                  1      398,07  \n",
       "\n",
       "[3615562 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_VTA_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e1e8b5",
   "metadata": {},
   "source": [
    "### Metadatos del dataset de Ventas Retail\n",
    "    Descripción breve de cada uno de los campos del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd75e2e",
   "metadata": {},
   "source": [
    "#### Maestro productos:\n",
    "    CODIGO_BARRAS_SKU: Código de barras identificatorio del producto (datos anonimizados).\n",
    "    CATEGORIA_SKU: Categoría correspondiente al producto (datos anonimizados).\n",
    "    MARCA_SKU: Marca correspondiente al producto (datos anonimizados).\n",
    "    PROVEEDOR_SKU: Proveedor correspondiente al producto (datos anonimizados). Agrupación uno a varios entre Proveedor y Marca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5201edcc",
   "metadata": {},
   "source": [
    "#### Maestro productos:\n",
    "    CODIGO_UNICO_PDV: Código identificatorio del cliente (datos anonimizados).\n",
    "    ZONA_P, ZONA_MODELO_B, AREA_P: Agrupaciones de CODIGO_UNICO_PDV, desde la mayor granularidad a la menor de manera correspondiente.\n",
    "    CLUSTER_PDV: Tipo de cliente, p.e. Autoservicio, Almacén, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19f4ca5",
   "metadata": {},
   "source": [
    "### Eliminación de duplicados\n",
    "    Como fue explicado arriba, debido a los procesos internos de la consultora, al realizar la unión de los distintos archivos fuente, existe una serie de registros duplicados que debemos tratar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9dd8d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maestro PDVs:\n",
      "Registros dataset original:  27297\n",
      "Registros dataset sin duplicados:  1834\n"
     ]
    }
   ],
   "source": [
    "df_PDV_001 = df_PDV_000.drop_duplicates(subset=['CODIGO_UNICO_PDV'])\n",
    "print('Maestro PDVs:')\n",
    "print('Registros dataset original: ',df_PDV_000.shape[0])\n",
    "print('Registros dataset sin duplicados: ',df_PDV_001.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d401513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot Table mostrando relación uno a varios de las agrupaciones de CODIGO_UNICO_PDV\n",
    "# df_PDV_001.pivot_table(index=['ZONA_P','ZONA_MODELO_B','AREA_P'], columns=None, aggfunc='count', values='CODIGO_UNICO_PDV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cb91f98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maestro SKUs:\n",
      "Registros dataset original:  32420\n",
      "Registros dataset sin duplicados:  2156\n"
     ]
    }
   ],
   "source": [
    "df_SKU_001 = df_SKU_000.drop_duplicates(subset=['CODIGO_BARRAS_SKU'])\n",
    "print('Maestro SKUs:')\n",
    "print('Registros dataset original: ',df_SKU_000.shape[0])\n",
    "print('Registros dataset sin duplicados: ',df_SKU_001.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8b45c63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maestro Ventas:\n",
      "Registros dataset original:  3615562\n",
      "Registros dataset sin duplicados:  2755115\n"
     ]
    }
   ],
   "source": [
    "df_VTA_001 = df_VTA_000.drop_duplicates(subset=['Semana_Inicio_Semana', 'CODIGO_UNICO_PDV_2', 'Codigo_Barras_SKU'])\n",
    "print('Maestro Ventas:')\n",
    "print('Registros dataset original: ',df_VTA_000.shape[0])\n",
    "print('Registros dataset sin duplicados: ',df_VTA_001.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c7828",
   "metadata": {},
   "source": [
    "### Tratamiento de datos nulos\n",
    "    Análisis de los datos nulos y su tratamiento, vía imputación o eliminación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b7d15c",
   "metadata": {},
   "source": [
    "#### Maestro productos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd41021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos CATEGORIA_SKU\n",
      "C457    483\n",
      "C158    361\n",
      "C749    285\n",
      "C575    268\n",
      "C353    262\n",
      "C920    217\n",
      "C168    145\n",
      "C340    135\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos MARCA_SKU\n",
      "OTRAS MARCAS    736\n",
      "M9037           117\n",
      "M8276            97\n",
      "M6800            69\n",
      "M8458            65\n",
      "               ... \n",
      "M1475             1\n",
      "M660              1\n",
      "M6358             1\n",
      "M7775             1\n",
      "M3095             1\n",
      "Name: count, Length: 150, dtype: int64\n",
      "\n",
      "Valores únicos PROVEEDOR_SKU\n",
      "OTROS PROVEEDORES    774\n",
      "P4872                327\n",
      "P6496                135\n",
      "P9774                 79\n",
      "P1532                 78\n",
      "                    ... \n",
      "P1084                  1\n",
      "P2103                  1\n",
      "P1509                  1\n",
      "P2285                  1\n",
      "P3195                  1\n",
      "Name: count, Length: 76, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Valores únicos incluyendo valores Null\n",
    "\n",
    "dataset = df_SKU_001\n",
    "index = 'CODIGO_BARRAS_SKU'\n",
    "for column in list(dataset.loc[:, dataset.columns != index]):\n",
    "    print('Valores únicos',dataset[column].value_counts(dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2cea8",
   "metadata": {},
   "source": [
    "El Maestro de productos por un lado no tiene valores nulos en el campo Categoría.\n",
    "\n",
    "Por otro lado, tiene productos con valores \"Otros\" en los campos Marca y Proveedor. Estos datos pueden ser considerados como datos nulos. Para entender el impacto de estos datos en el total, veremos la facturación que representan vs el resto de las marcas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdade0",
   "metadata": {},
   "source": [
    "#### Maestro Clientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d7d542b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos AREA_P\n",
      "Interior         1280\n",
      "Metropolitana     554\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos ZONA_P\n",
      "C.A.B.A                   185\n",
      "CORDOBA INTERIOR          174\n",
      "COSTA ATLANTICA           131\n",
      "GBA SUR                   131\n",
      "CORDOBA CAPITAL           114\n",
      "GBA NORTE                 112\n",
      "MENDOZA INTERIOR          104\n",
      "ROSARIO                   101\n",
      "SANTA FE INTERIOR          95\n",
      "GBA OESTE                  93\n",
      "BUENOS AIRES INTERIOR      79\n",
      "BAHIA BLANCA               71\n",
      "TUCUMAN INTERIOR           45\n",
      "LA PLATA                   33\n",
      "TUCUMAN CAPITAL            32\n",
      "SAN JUAN INTERIOR          30\n",
      "RIO NEGRO INTERIOR         30\n",
      "SANTA FE CAPITAL           29\n",
      "SAN JUAN CAPITAL           26\n",
      "CHACO RESISTENCIA          25\n",
      "ENTRE RIOS INTERIOR        24\n",
      "CHACO INTERIOR             22\n",
      "NEUQUEN                    18\n",
      "ENTRE RIOS PARANA          18\n",
      "CORRIENTES CAPITAL         15\n",
      "CORRIENTES INTERIOR        14\n",
      "MISIONES INTERIOR          13\n",
      "MISIONES POSADAS           11\n",
      "MENDOZA CAPITAL             9\n",
      "SALTA CAPITAL               7\n",
      "SANTIAGO CAPITAL            6\n",
      "SANTIAGO INTERIOR           5\n",
      "FORMOSA CAPITAL             5\n",
      "SAN LUIS INTERIOR           5\n",
      "LA RIOJA INTERIOR           4\n",
      "RIO NEGRO CAPITAL           4\n",
      "LA RIOJA CAPITAL            4\n",
      "CHUBUT INTERIOR             3\n",
      "SALTA INTERIOR              2\n",
      "JUJUY CAPITAL               2\n",
      "LA PAMPA INTERIOR           1\n",
      "CATAMARCA CAPITAL           1\n",
      "SAN LUIS METROPOLITANA      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos CLUSTER_PDV\n",
      "Autoservicio Chico         510\n",
      "Grupo Cadena               358\n",
      "Autoservicio Mediano       217\n",
      "NaN                        166\n",
      "Kiosco                     154\n",
      "Autoservicio Grande        141\n",
      "Almacen                    112\n",
      "Supermercado               109\n",
      "Mayoristas                  29\n",
      "No Clasifica                 9\n",
      "Vinoteca                     8\n",
      "Pañalera                     7\n",
      "Panaderia                    4\n",
      "Carniceria                   3\n",
      "Distribuidora                3\n",
      "Casa_Articulos_Limpieza      2\n",
      "Perfumeria                   2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Valores únicos ZONA_MODELO_B\n",
      "PCIA BS AS y SUR    337\n",
      "CORDOBA             288\n",
      "LITORAL             267\n",
      "CAPITAL FEDERAL     185\n",
      "CUYO                175\n",
      "SUB SUR             164\n",
      "SUB NORTE           112\n",
      "NOA                 108\n",
      "NEA                 105\n",
      "SUB OESTE            93\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Valores únicos incluyendo valores Null\n",
    "\n",
    "dataset = df_PDV_001\n",
    "index = 'CODIGO_UNICO_PDV'\n",
    "for column in list(dataset.loc[:, dataset.columns != index]):\n",
    "    print('Valores únicos',dataset[column].value_counts(dropna=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5a0786",
   "metadata": {},
   "source": [
    "Los clientes parecen encontrarse correctamente clasificados por Zona, pero presentan varios datos nulos enlo que respecta a su clasificación por Clúster. Lidiaremos con estos datos nulos luego de ver su contribución al total de la facturación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186db2f",
   "metadata": {},
   "source": [
    "### Combinación de las tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07731e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar el merge con el Maestro Clientes\n",
    "df_VTA_002 = df_VTA_001.merge(df_PDV_001, left_on='CODIGO_UNICO_PDV_2', right_on='CODIGO_UNICO_PDV', how='left')\n",
    "\n",
    "# Realizar el merge con el Maestro Productos\n",
    "df_VTA_003 = df_VTA_002.merge(df_SKU_001, left_on='Codigo_Barras_SKU', right_on='CODIGO_BARRAS_SKU', how='left')\n",
    "\n",
    "#Borrar claves duplicadas en el merge\n",
    "df_VTA_004 = df_VTA_003.drop(['CODIGO_UNICO_PDV_2', 'Codigo_Barras_SKU'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtrar la facturación de \"OTRAS MARCAS\"\n",
    "# otras_marcas_facturacion = df_VTA_004[df_VTA_004['MARCA_SKU'] == 'OTRAS MARCAS']['Facturación'].sum()\n",
    "\n",
    "# # Calcular la facturación del \"Resto\"\n",
    "# resto_facturacion = df_VTA_004[df_VTA_004['MARCA_SKU'] != 'OTRAS MARCAS']['Facturación'].sum()\n",
    "\n",
    "# # Crear un dataframe con los valores para el gráfico de torta\n",
    "# facturacion_data = pd.DataFrame({\n",
    "#     'Categoría': ['OTRAS MARCAS', 'Resto'],\n",
    "#     'Facturación': [otras_marcas_facturacion, resto_facturacion]\n",
    "# })\n",
    "\n",
    "# # Crear el gráfico de torta\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.pie(facturacion_data['Facturación'], labels=facturacion_data['Categoría'], autopct='%1.1f%%', startangle=140)\n",
    "# plt.title('Distribución de Facturación entre OTRAS MARCAS y el Resto')\n",
    "# plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "# # Mostrar el gráfico\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
